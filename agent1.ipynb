{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5583265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# import boto3\n",
    "from dotenv import load_dotenv\n",
    "import io\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_community.chat_models import BedrockChat, OllamaChat\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from pprint import pprint\n",
    "from contextlib import redirect_stdout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae952e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a73b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\7N1103703624199\\AppData\\Local\\Temp\\ipykernel_3672\\925134004.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  dotenv_path = 'C:\\data-scientist-ai-agent\\.env'\n"
     ]
    }
   ],
   "source": [
    "dotenv_path = 'C:\\data-scientist-ai-agent\\.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f14bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was the .env file loaded? -> False\n"
     ]
    }
   ],
   "source": [
    "is_loaded = load_dotenv(dotenv_path=dotenv_path, override=True)\n",
    "print(f\"Was the .env file loaded? -> {is_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4134df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "c:\\data-scientist-ai-agent\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "aws_session_token=os.getenv(\"AWS_SESSION_TOKEN\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatBedrock(region_name=\"us-east-1\", model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\", model_kwargs={\"temperature\": 0.0})\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1774a94",
   "metadata": {},
   "source": [
    "Get Data Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa25a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_dataframe_info() -> str:\n",
    "    \"\"\"\n",
    "    Returns a full summary of the DataFrame including column names, non-null counts, and data types.\n",
    "    Use this first to get a general understanding of the dataset's structure.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    buffer = io.StringIO()\n",
    "    df.info(buf=buffer)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "@tool\n",
    "def get_dataframe_head(n: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Returns the first n rows of the DataFrame as a string.\n",
    "    Useful for inspecting the actual data values. 'n' defaults to 5.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    return df.head(n).to_string()\n",
    "\n",
    "@tool\n",
    "def get_descriptive_stats() -> str:\n",
    "    \"\"\"\n",
    "    Returns descriptive statistics for the numerical columns in the DataFrame, \n",
    "    including count, mean, std, min, max, and percentiles.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    return df.describe().to_string()\n",
    "\n",
    "@tool\n",
    "def get_value_counts(column: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the count of unique values for a specified column.\n",
    "    Best used for categorical columns like 'Sex', 'Pclass', or 'Embarked'.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    if column not in df.columns:\n",
    "        return f\"Error: Column '{column}' not found in the DataFrame.\"\n",
    "    return df[column].value_counts().to_string()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4a678",
   "metadata": {},
   "source": [
    "Edit Data Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def drop_columns(columns: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Drops one or more specified columns from the DataFrame.\n",
    "    The input should be a list of column name strings.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    try:\n",
    "        df.drop(columns=columns, axis=1, inplace=True)\n",
    "        return f\"Successfully dropped columns: {columns}. Use get_dataframe_info to see the new structure.\"\n",
    "    except KeyError as e:\n",
    "        return f\"Error: One or more columns not found: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "@tool\n",
    "def fill_missing_age_with_median() -> str:\n",
    "    \"\"\"\n",
    "    Calculates the median of the 'Age' column and fills any missing values in that column with the median.\n",
    "    This should only be used for the 'Age' column.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    if 'Age' not in df.columns:\n",
    "        return \"Error: 'Age' column not found.\"\n",
    "    \n",
    "    median_age = df['Age'].median()\n",
    "    df['Age'].fillna(median_age, inplace=True)\n",
    "    return f\"Successfully filled missing 'Age' values with the median value of {median_age}.\"\n",
    "\n",
    "@tool\n",
    "def create_familysize_feature() -> str:\n",
    "    \"\"\"\n",
    "    Creates a new column 'FamilySize' by adding the 'SibSp' and 'Parch' columns together.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    if 'SibSp' in df.columns and 'Parch' in df.columns:\n",
    "        df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "        return \"Successfully created the 'FamilySize' feature.\"\n",
    "    else:\n",
    "        return \"Error: 'SibSp' or 'Parch' columns not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ef8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    get_dataframe_info,\n",
    "    get_dataframe_head,\n",
    "    get_descriptive_stats,\n",
    "    get_value_counts,\n",
    "    drop_columns,\n",
    "    fill_missing_age_with_median,\n",
    "    create_familysize_feature,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert Data Scientist assistant. Your goal is to help the user with Exploratory Data Analysis (EDA) and Feature Engineering.\n",
    "\n",
    "You have access to a set of tools to inspect and manipulate a pandas DataFrame.\n",
    "\n",
    "**Thinking Process:**\n",
    "1.  **Understand the Goal:** Analyze the user's request.\n",
    "2.  **Inspect:** ALWAYS use your inspection tools (`get_dataframe_info`, `get_dataframe_head`, etc.) to understand the current state of the DataFrame before taking any action. Do not assume the state.\n",
    "3.  **Plan:** Decide which tool is appropriate for the user's request.\n",
    "4.  **Act:** Execute the chosen tool.\n",
    "5.  **Observe & Respond:** Analyze the output from the tool and provide a clear, helpful summary to the user.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f505f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787830ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent =  create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaff090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "  chat_history = []\n",
    "  for human, assistant in history:\n",
    "    chat_history.append(HumanMessage(content=human))\n",
    "    chat_history.append(AIMessage(content=assistant))\n",
    "\n",
    "  response = agent_executor.invoke({\n",
    "    \"input\":message,\n",
    "    \"chat_history\":chat_history\n",
    "  })\n",
    "  return response[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041172b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bedrock_client(\n",
    "    aws_access_key_id, aws_secret_access_key, aws_session_token\n",
    "):\n",
    "    return boto3.client(\n",
    "        \"bedrock-runtime\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        aws_session_token=aws_session_token,\n",
    "        region_name=REGION_NAME,\n",
    "        # config=custom_config,\n",
    "    )\n",
    " \n",
    "REGION_NAME = \"us-east-1\"\n",
    "MODEL_ID = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    " \n",
    "# Setting AWS key\n",
    "# AWS_ACCESS_KEY_ID = \"\"\n",
    "# AWS_SECRET_ACCESS_KEY = \"\"\n",
    "# AWS_SESSION_TOKEN = \"\"\n",
    " \n",
    "# custom_config = Config(\n",
    "#     read_timeout=400,\n",
    "#     connect_timeout=400,\n",
    "#     retries={\"max_attempts\": 3},\n",
    "# )\n",
    "bedrock_runtime = initialize_bedrock_client(\n",
    "        aws_access_key_id, aws_secret_access_key, aws_session_token\n",
    "    )\n",
    "llm = BedrockChat(model_id=MODEL_ID, client=bedrock_runtime)\n",
    " \n",
    "system_template = \"\"\"You are a female who is specialized in financial analysis and credit analysis for auto loans. Your task is to analyze financial data and provide insights.\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template_company_fin = \"\"\"Analyze the following data {company_profile}.\"\"\"\n",
    " \n",
    "human_message_prompt_company_fin = HumanMessagePromptTemplate.from_template(\n",
    "        human_template_company_fin\n",
    "    )\n",
    "chat_prompt_comp_info = ChatPromptTemplate.from_messages(\n",
    "        [system_message_prompt, human_message_prompt_company_fin]\n",
    "    )\n",
    "messages_comp_info = chat_prompt_comp_info.format_prompt(\n",
    "        company_profile=\"The company is a leading auto loan provider with a diverse portfolio of customers. The company has been in operation for over 10 years and has a strong market presence. The company offers competitive interest rates and flexible repayment options to its customers. The company has a robust risk management framework in place to mitigate potential losses.\"\n",
    "    ).to_messages()\n",
    " \n",
    "response = llm.invoke(\n",
    "        messages_comp_info, temperature=0.0, max_tokens=4096, top_p=0.9999\n",
    "    )\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2381890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
