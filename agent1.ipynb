{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5583265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# import boto3\n",
    "from dotenv import load_dotenv\n",
    "import io\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import BedrockChat, ChatOllama\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cae952e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4134df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "c:\\data-scientist-ai-agent\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b8e4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "# aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "# aws_session_token=os.getenv(\"AWS_SESSION_TOKEN\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91c1f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatBedrock(region_name=\"us-east-1\", model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\", model_kwargs={\"temperature\": 0.0})\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "# llm = ChatOllama(model=\"llama3\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4f5481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_dict = {}\n",
    "df_dict['train'] = pd.read_csv('train.csv')\n",
    "df_dict['test'] = pd.read_csv('test.csv')\n",
    "print(df_dict['train'].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e73f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1774a94",
   "metadata": {},
   "source": [
    "Get Data Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fa25a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_dataframe_info(df_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a full summary of the DataFrame including column names, non-null counts, and data types.\n",
    "    Use this first to get a general understanding of the dataset's structure.\n",
    "    You must specify the DataFrame name. For example if DaTaframe name is 'train' use df_name = 'train' \n",
    "    \"\"\"\n",
    "    \n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    \n",
    "    buffer = io.StringIO()\n",
    "    df_dict[df_name].info(buf=buffer)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "@tool\n",
    "def get_dataframe_head(df_name: str ,n: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Returns the first n rows of the DataFrame as a string.\n",
    "    Useful for inspecting the actual data values. 'n' defaults to 5.\n",
    "    \"\"\"\n",
    "    \n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    \n",
    "    return df_dict[df_name].head(n).to_string()\n",
    "\n",
    "@tool\n",
    "def get_descriptive_stats(df_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns descriptive statistics for the numerical columns in the DataFrame, \n",
    "    including count, mean, std, min, max, and percentiles.\n",
    "    \"\"\"\n",
    "    \n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    return df_dict[df_name].describe().to_string()\n",
    "\n",
    "@tool\n",
    "def get_value_counts(df_name: str, column: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the count of unique values for a specified column in DataFrame name.\n",
    "    Best used for categorical columns like 'Sex', 'Pclass', or 'Embarked'.\n",
    "    \"\"\"\n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    if column not in df_dict[df_name].columns:\n",
    "        return f\"Error: Column '{column}' not found in the DataFrame.\"\n",
    "    return df_dict[df_name][column].value_counts().to_string()\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_value_column_at_index(df_name: str, column_name: str, index: int) -> str:\n",
    "    \"\"\"\n",
    "    Return column name value at this index in the DataFrame\n",
    "    \"\"\"\n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    \n",
    "    if column_name not in df_dict[df_name].columns:\n",
    "        return f\"Error: Column '{column_name}' not found in the DataFrame.\"\n",
    "    else:\n",
    "        if index >= len(df_dict[df_name]):\n",
    "            return f\"Error: index {index} if out of range\"\n",
    "        return df_dict[df_name].iloc[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4a678",
   "metadata": {},
   "source": [
    "Edit Data Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd66e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "516c297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\data-scientist-ai-agent\\venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:628: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\data-scientist-ai-agent\\venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:628: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def drop_columns(df_name: str, columns: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Drops one or more specified columns from the DataFrame name.\n",
    "    The input should be a list of column name strings.\n",
    "    \"\"\"\n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    try:\n",
    "        df_dict[df_name].drop(columns=columns, axis=1, inplace=True)\n",
    "        return f\"Successfully dropped columns: {columns}. Use get_dataframe_info to see the new structure.\"\n",
    "    except KeyError as e:\n",
    "        return f\"Error: One or more columns not found: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "@tool\n",
    "def add_column_from_expression(df_name: str, new_column_name: str, col1: str, operator: str, col2: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates a new column by performing a mathematical operation (+, -, *, /) on two existing columns.\n",
    "    For example, to create a new column 'C' by adding 'A' and 'B', the arguments would be:\n",
    "    new_column_name='C', col1='A', operator='+', col2='B'.\n",
    "    \"\"\"\n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    \n",
    "    # --- Input Validation ---\n",
    "    if new_column_name in df_dict[df_name].columns:\n",
    "        return f\"Error: Column '{new_column_name}' already exists. Please choose a different name.\"\n",
    "    if col1 not in df_dict[df_name].columns:\n",
    "        return f\"Error: Column '{col1}' not found in the DataFrame.\"\n",
    "    if col2 not in df_dict[df_name].columns:\n",
    "        return f\"Error: Column '{col2}' not found in the DataFrame.\"\n",
    "    \n",
    "    valid_operators = ['+', '-', '*', '/']\n",
    "    if operator not in valid_operators:\n",
    "        return f\"Error: Invalid operator '{operator}'. Please use one of {valid_operators}.\"\n",
    "\n",
    "    # --- Operation Logic ---\n",
    "    try:\n",
    "        if operator == '+':\n",
    "            df_dict[df_name][new_column_name] = df_dict[col1] + df_dict[col2]\n",
    "        elif operator == '-':\n",
    "            df_dict[df_name][new_column_name] = df_dict[col1] - df_dict[col2]\n",
    "        elif operator == '*':\n",
    "            df_dict[df_name][new_column_name] = df_dict[col1] * df_dict[col2]\n",
    "        elif operator == '/':\n",
    "            # Add a small number to avoid division by zero\n",
    "            df_dict[df_name][new_column_name] = df_dict[col1] / (df_dict[col2] + 1e-6)\n",
    "        \n",
    "        return df_dict[df_name]\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during the operation: {e}\"\n",
    "    \n",
    "@tool\n",
    "def update_value_based_on_condition(df_name: str, target_column: str, new_value: any, condition_column: str, condition_value: any) -> str:\n",
    "    \"\"\"\n",
    "    Updates values in a 'target_column' to a 'new_value' wherever a condition is met in the 'condition_column'.\n",
    "    This is equivalent to: df.loc[df['condition_column'] == condition_value, 'target_column'] = new_value\n",
    "    Example: To change the 'Fare' to 0 for all 3rd class ('Pclass' is 3) passengers, you would use:\n",
    "    target_column='Fare', new_value=0, condition_column='Pclass', condition_value=3\n",
    "    \"\"\"\n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    \n",
    "    # --- Input Validation ---\n",
    "    if target_column not in df_dict[df_name].columns:\n",
    "        return f\"Error: The target column '{target_column}' was not found in the DataFrame.\"\n",
    "    if condition_column not in df_dict[df_name].columns:\n",
    "        return f\"Error: The condition column '{condition_column}' was not found in the DataFrame.\"\n",
    "    \n",
    "    try:\n",
    "        # Check if the condition value exists in the condition column to prevent silent failures\n",
    "        if condition_value not in df_dict[df_name][condition_column].unique():\n",
    "            print(f\"Warning: The condition value '{condition_value}' does not exist in the column '{condition_column}'. No rows will be changed.\")\n",
    "\n",
    "        # --- Core Logic ---\n",
    "        # Get the original data type of the target column\n",
    "        original_dtype = df_dict[df_name][target_column].dtype\n",
    "        \n",
    "        # Perform the update\n",
    "        df_dict[df_name].loc[df[condition_column] == condition_value, target_column] = new_value\n",
    "        \n",
    "        # Try to convert the column back to its original type if possible\n",
    "        df_dict[df_name][target_column] = df_dict[df_name][target_column].astype(original_dtype)\n",
    "\n",
    "        return df_dict[df_name]\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while trying to update the column: {e}\"\n",
    "\n",
    "@tool\n",
    "def split_column(df_name: str, column_name: str, delimiter: str, new_column_name: list) -> str:\n",
    "    \"\"\" Splits a single text column into multiple new columns based on a specified delimiter.\n",
    "    You must provide a list of names for the new columns. The number of new names should match the number of expected split parts.\n",
    "    Example: To split the 'Name' column (e.g., \"Braund, Mr. Owen Harris\") into 'LastName' and 'FirstName', you would use:\n",
    "    column_name='Name', delimiter=',', new_column_names=['LastName', 'FirstName'] \"\"\"\n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    \n",
    "    df = df_dict[df_name]\n",
    "    if column_name not in df.columns:\n",
    "        return f\"Error: Column '{column_name}' not found in the DataFrame.\"\n",
    "    df[column_name] \n",
    "\n",
    "    if not pd.api.types.is_string_dtype(df[column_name]):\n",
    "        return f\"Error: Column '{column_name}' is not a text/string column. It cannot be split.\"\n",
    "\n",
    "    for new_col in new_column_name:\n",
    "        if new_col in df.columns:\n",
    "            return f\"Error: A column named '{new_col}' already exists. Please choose different names.\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        split_data = df[column_name].str.split(delimiter, n=len(new_column_name)-1, expand=True)\n",
    "        df[new_column_name] = split_data\n",
    "        if split_data.shape[1] < len(new_column_name):\n",
    "             return (f\"Error: The split operation on '{column_name}' with delimiter '{delimiter}' \"\n",
    "                     f\"produced fewer columns ({split_data.shape[1]}) than the number of new names provided ({len(new_column_name)}). \"\n",
    "                     \"Some rows might not contain the delimiter.\")\n",
    "\n",
    "        # 6. Assign the new data to the new columns in the DataFrame\n",
    "        df[new_column_name] = split_data\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during the split operation: {e}\"\n",
    "    \n",
    "\n",
    "@tool\n",
    "def fill_missing_age_with_median(df_name: str, column_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculates the median of the column name and fills any missing values in that column with the median.\n",
    "    \"\"\"\n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    df = df_dict[df_name]\n",
    "    if column_name not in df.columns:\n",
    "        return f\"Error: '{column_name}' column not found.\"\n",
    "    \n",
    "    median = df[column_name].median()\n",
    "    df[column_name].fillna(median, inplace=True)\n",
    "    return f\"Successfully filled missing {column_name} values with the median value of {median}.\"\n",
    "\n",
    "@tool\n",
    "def create_new_column_by_suming_column(df_name: str, column_name: list, new_column_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates a new column by summing the values of multiple specified numerical columns for each row.\n",
    "    Example: To create a 'FamilySize' column by adding 'SibSp' and 'Parch', you would use:\n",
    "    column_names=['SibSp', 'Parch'], new_column_name='FamilySize'\n",
    "    \"\"\"\n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    df = df_dict[df_name]\n",
    "    if new_column_name in df.columns:\n",
    "        return f\"error column {new_column_name} have already exist\"\n",
    "    else:\n",
    "        for column in column_name:\n",
    "            if column not in df.columns:\n",
    "                return f\"Error The column {column} not found in the Dataframe\"\n",
    "            if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "                return f\"Error: The column '{column}' is not a numerical column and cannot be summed.\"\n",
    "    try:\n",
    "        df[new_column_name] = df[column_name].sum(axis=1)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred: {e}\"\n",
    "\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c7847",
   "metadata": {},
   "source": [
    "Data Visialization Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7d29946",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def plot_correlation_heatmap(df_name: str, filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates and saves a heatmap of the correlation matrix for all numerical columns in the DataFrame.\n",
    "    This helps to quickly see which variables are correlated. The plot is saved as an image file.\n",
    "    Example: To generate the heatmap, use filename='correlation_heatmap.png'\n",
    "    \"\"\"\n",
    "    if df_name not in df_dict:\n",
    "        return f\"Error : DataFrame {df_name} not found. Available DataFrames are: {list(df_dict.keys())}\"\n",
    "    df = df_dict[df_name]\n",
    "    \n",
    "    try:\n",
    "        # 1. เลือกเฉพาะคอลัมน์ที่เป็นตัวเลข\n",
    "        numerical_df = df.select_dtypes(include=['number'])\n",
    "        \n",
    "        # 2. คำนวณ Correlation Matrix\n",
    "        corr_matrix = numerical_df.corr()\n",
    "        \n",
    "        # 3. สร้าง Heatmap ด้วย Seaborn\n",
    "        plt.figure(figsize=(12, 10)) # กำหนดขนาดของรูปภาพให้ใหญ่พอดี\n",
    "        sns.heatmap(\n",
    "            corr_matrix, \n",
    "            annot=True,      # แสดงตัวเลขค่า correlation ในแต่ละช่อง\n",
    "            cmap='coolwarm', # เลือกโทนสี (สีอุ่น = correlation บวก, สีเย็น = correlation ลบ)\n",
    "            fmt='.2f'        # จัดรูปแบบทศนิยม 2 ตำแหน่ง\n",
    "        )\n",
    "        \n",
    "        # 4. ตั้งชื่อกราฟ\n",
    "        plt.title('Correlation Heatmap of Numerical Columns')\n",
    "        \n",
    "        # 5. บันทึกรูปภาพเป็นไฟล์\n",
    "        # bbox_inches='tight' ช่วยให้ไม่เกิดการตัดขอบของตัวอักษร\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "        \n",
    "        # 6. ปิด Plot เพื่อไม่ให้แสดงผลใน Notebook โดยไม่จำเป็นและคืนค่าหน่วยความจำ\n",
    "        plt.close()\n",
    "        \n",
    "        return f\"Correlation heatmap for numerical columns was successfully generated and saved to '{filename}'.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while generating the heatmap: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d715ae8",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "029904db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def train_classification_model(dataframe_name: str, feature_columns: list[str], target_column: str) -> str:\n",
    "    \"\"\"\n",
    "    Trains a classification model (RandomForest) on the specified DataFrame.\n",
    "    It automatically handles categorical features using One-Hot Encoding, splits data into training and testing sets (80/20 split),\n",
    "    trains the model, and returns a report with the model's performance metrics (Accuracy and Classification Report).\n",
    "\n",
    "    Example: To predict 'Survived' using 'Pclass', 'Sex', 'Age', and 'FamilySize' from the 'train' dataframe, use:\n",
    "    dataframe_name='train', \n",
    "    feature_columns=['Pclass', 'Sex', 'Age', 'FamilySize'], \n",
    "    target_column='Survived'\n",
    "    \"\"\"\n",
    "    global dataframes # ใช้ dataframes dictionary ที่เราสร้างไว้\n",
    "    \n",
    "    # --- 1. Validation ---\n",
    "    if dataframe_name not in dataframes:\n",
    "        return f\"Error: DataFrame '{dataframe_name}' not found. Available dataframes are: {list(dataframes.keys())}\"\n",
    "    \n",
    "    df_to_use = dataframes[dataframe_name].copy() # ใช้ .copy() เพื่อป้องกันการแก้ไข DataFrame ต้นฉบับโดยไม่ตั้งใจ\n",
    "    \n",
    "    all_columns = feature_columns + [target_column]\n",
    "    for col in all_columns:\n",
    "        if col not in df_to_use.columns:\n",
    "            return f\"Error: Column '{col}' not found in DataFrame '{dataframe_name}'.\"\n",
    "\n",
    "    # --- 2. Data Preparation ---\n",
    "    try:\n",
    "        # 2a. จัดการค่าว่างใน Feature (วิธีง่ายๆ คือการลบแถวที่มีค่าว่าง)\n",
    "        # ในการใช้งานจริง อาจจะต้องสร้าง Tool fillna ที่ซับซ้อนกว่านี้ก่อน\n",
    "        df_clean = df_to_use[all_columns].dropna()\n",
    "        original_rows = len(df_to_use)\n",
    "        clean_rows = len(df_clean)\n",
    "        if clean_rows < original_rows:\n",
    "            print(f\"Warning: Dropped {original_rows - clean_rows} rows with missing values before training.\")\n",
    "\n",
    "        X = df_clean[feature_columns]\n",
    "        y = df_clean[target_column]\n",
    "\n",
    "        # 2b. แยกประเภทคอลัมน์สำหรับ Preprocessing\n",
    "        categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "        numerical_features = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "        # --- 3. Create Preprocessing Pipeline ---\n",
    "        # สร้าง transformer เพื่อจัดการกับคอลัมน์แต่ละประเภท\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', numerical_features), # ไม่ทำอะไรกับคอลัมน์ตัวเลข (ถ้าต้อง scale ค่อยเพิ่มทีหลัง)\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features) # แปลงคอลัมน์ข้อความเป็น One-Hot Encoding\n",
    "            ])\n",
    "\n",
    "        # --- 4. Define Model ---\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        # --- 5. Create and Train Full Pipeline ---\n",
    "        # รวมขั้นตอน Preprocessing และ Model เข้าด้วยกัน\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('classifier', model)])\n",
    "\n",
    "        # 5a. Split data for training and evaluation\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # 5b. Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # --- 6. Evaluation ---\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        # --- 7. Format Output ---\n",
    "        result_str = (\n",
    "            f\"Model training completed on DataFrame '{dataframe_name}'.\\n\"\n",
    "            f\"Features used: {feature_columns}\\n\"\n",
    "            f\"Target variable: {target_column}\\n\\n\"\n",
    "            f\"--- Model Performance Report ---\\n\"\n",
    "            f\"Accuracy: {accuracy:.4f}\\n\\n\"\n",
    "            f\"Classification Report:\\n{report}\"\n",
    "        )\n",
    "        return result_str\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during model training or evaluation: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f7ef8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    get_dataframe_info,\n",
    "    get_dataframe_head,\n",
    "    get_descriptive_stats,\n",
    "    get_value_counts,\n",
    "    drop_columns,\n",
    "    fill_missing_age_with_median,\n",
    "    create_new_column_by_suming_column,\n",
    "    add_column_from_expression,\n",
    "    update_value_based_on_condition,\n",
    "    split_column,\n",
    "    plot_correlation_heatmap,\n",
    "    get_value_column_at_index,\n",
    "    train_classification_model\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "930e62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert Data Scientist assistant. Your goal is to help the user with Exploratory Data Analysis (EDA) and Feature Engineering.\n",
    "\n",
    "You have access to a set of tools to inspect and manipulate a pandas DataFrame.\n",
    "\n",
    "**Thinking Process:**\n",
    "1.  **Understand the Goal:** Analyze the user's request.\n",
    "2.  **Inspect:** ALWAYS use your inspection tools (`get_dataframe_info`, `get_dataframe_head`, etc.) to understand the current state of the DataFrame before taking any action. Do not assume the state.\n",
    "3.  **Plan:** Decide which tool is appropriate for the user's request.\n",
    "4.  **Act:** Execute the chosen tool.\n",
    "5.  **Observe & Respond:** Analyze the output from the tool and provide a clear, helpful summary to the user.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f505f50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001BE0075B920>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001BE0075B920>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"\\nYou are an expert Data Scientist assistant. Your goal is to help the user with Exploratory Data Analysis (EDA) and Feature Engineering.\\n\\nYou have access to a set of tools to inspect and manipulate a pandas DataFrame.\\n\\n**Thinking Process:**\\n1.  **Understand the Goal:** Analyze the user's request.\\n2.  **Inspect:** ALWAYS use your inspection tools (`get_dataframe_info`, `get_dataframe_head`, etc.) to understand the current state of the DataFrame before taking any action. Do not assume the state.\\n3.  **Plan:** Decide which tool is appropriate for the user's request.\\n4.  **Act:** Execute the chosen tool.\\n5.  **Observe & Respond:** Analyze the output from the tool and provide a clear, helpful summary to the user.\\n\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "787830ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\data-scientist-ai-agent\\venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:628: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "agent =  create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abaff090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "  chat_history = []\n",
    "  for human, assistant in history:\n",
    "    chat_history.append(HumanMessage(content=human))\n",
    "    chat_history.append(AIMessage(content=assistant))\n",
    "\n",
    "  response = agent_executor.invoke({\n",
    "    \"input\":message,\n",
    "    \"chat_history\":chat_history\n",
    "  })\n",
    "  return response[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "041172b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\data-scientist-ai-agent\\venv\\Lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c36dd4b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m].info()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_dataframe_info` with `{'df_name': 'train'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `drop_columns` with `{'df_name': 'train', 'columns': ['PassengerId']}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mSuccessfully dropped columns: ['PassengerId']. Use get_dataframe_info to see the new structure.\u001b[0m\u001b[32;1m\u001b[1;3mThe column `PassengerId` has been successfully removed from the `train` DataFrame. If you need further assistance or want to inspect the updated DataFrame, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_descriptive_stats` with `{'df_name': 'train'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m         Survived      Pclass         Age       SibSp       Parch        Fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\u001b[0m\u001b[32;1m\u001b[1;3mHere are the descriptive statistics for the numerical columns in the `train` DataFrame:\n",
      "\n",
      "- **Survived**:\n",
      "  - Count: 891\n",
      "  - Mean: 0.384\n",
      "  - Standard Deviation: 0.487\n",
      "  - Min: 0\n",
      "  - 25th Percentile: 0\n",
      "  - 50th Percentile (Median): 0\n",
      "  - 75th Percentile: 1\n",
      "  - Max: 1\n",
      "\n",
      "- **Pclass**:\n",
      "  - Count: 891\n",
      "  - Mean: 2.309\n",
      "  - Standard Deviation: 0.836\n",
      "  - Min: 1\n",
      "  - 25th Percentile: 2\n",
      "  - 50th Percentile (Median): 3\n",
      "  - 75th Percentile: 3\n",
      "  - Max: 3\n",
      "\n",
      "- **Age**:\n",
      "  - Count: 714 (Note: There are missing values)\n",
      "  - Mean: 29.699\n",
      "  - Standard Deviation: 14.526\n",
      "  - Min: 0.42\n",
      "  - 25th Percentile: 20.125\n",
      "  - 50th Percentile (Median): 28\n",
      "  - 75th Percentile: 38\n",
      "  - Max: 80\n",
      "\n",
      "- **SibSp** (Number of Siblings/Spouses aboard):\n",
      "  - Count: 891\n",
      "  - Mean: 0.523\n",
      "  - Standard Deviation: 1.103\n",
      "  - Min: 0\n",
      "  - 25th Percentile: 0\n",
      "  - 50th Percentile (Median): 0\n",
      "  - 75th Percentile: 1\n",
      "  - Max: 8\n",
      "\n",
      "- **Parch** (Number of Parents/Children aboard):\n",
      "  - Count: 891\n",
      "  - Mean: 0.382\n",
      "  - Standard Deviation: 0.806\n",
      "  - Min: 0\n",
      "  - 25th Percentile: 0\n",
      "  - 50th Percentile (Median): 0\n",
      "  - 75th Percentile: 0\n",
      "  - Max: 6\n",
      "\n",
      "- **Fare**:\n",
      "  - Count: 891\n",
      "  - Mean: 32.204\n",
      "  - Standard Deviation: 49.693\n",
      "  - Min: 0\n",
      "  - 25th Percentile: 7.910\n",
      "  - 50th Percentile (Median): 14.454\n",
      "  - 75th Percentile: 31\n",
      "  - Max: 512.329\n",
      "\n",
      "If you need further analysis or have any questions, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_descriptive_stats` with `{'df_name': 'train'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m         Survived      Pclass         Age       SibSp       Parch        Fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\u001b[0m\u001b[32;1m\u001b[1;3mThe minimum age in the `train` DataFrame is 0.42 years. If you have any more questions or need further analysis, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_descriptive_stats` with `{'df_name': 'train'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m         Survived      Pclass         Age       SibSp       Parch        Fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\u001b[0m\u001b[32;1m\u001b[1;3mThe maximum age in the `train` DataFrame is 80 years. If you have any more questions or need further analysis, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_value_column_at_index` with `{'df_name': 'train', 'column_name': 'Age', 'index': 800}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSurvived                       0\n",
      "Pclass                         2\n",
      "Name        Ponesell, Mr. Martin\n",
      "Sex                         male\n",
      "Age                         34.0\n",
      "SibSp                          0\n",
      "Parch                          0\n",
      "Ticket                    250647\n",
      "Fare                        13.0\n",
      "Cabin                        NaN\n",
      "Embarked                       S\n",
      "Name: 800, dtype: object\u001b[0m\u001b[32;1m\u001b[1;3mThe age of the passenger at index 800 in the `train` DataFrame is 34.0 years. If you have any more questions or need further assistance, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df['train'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b7700",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aws_access_key_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[208]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     14\u001b[39m MODEL_ID = \u001b[33m\"\u001b[39m\u001b[33manthropic.claude-3-5-sonnet-20240620-v1:0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Setting AWS key\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# AWS_ACCESS_KEY_ID = \"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# AWS_SECRET_ACCESS_KEY = \"\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#     retries={\"max_attempts\": 3},\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     26\u001b[39m bedrock_runtime = initialize_bedrock_client(\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         \u001b[43maws_access_key_id\u001b[49m, aws_secret_access_key, aws_session_token\n\u001b[32m     28\u001b[39m     )\n\u001b[32m     29\u001b[39m llm = BedrockChat(model_id=MODEL_ID, client=bedrock_runtime)\n\u001b[32m     31\u001b[39m system_template = \u001b[33m\"\"\"\u001b[39m\u001b[33mYou are a female who is specialized in financial analysis and credit analysis for auto loans. Your task is to analyze financial data and provide insights.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'aws_access_key_id' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo fill the missing values in the \"Age\" column, I will first inspect the DataFrame to ensure I understand its current state. Then, I will fill the missing values with the median of the \"Age\" column. Let's start by inspecting the DataFrame. Could you please provide the name of the DataFrame you are working with?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_dataframe_info` with `{'df_name': 'train'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fill_missing_age_with_median` with `{'df_name': 'train', 'column_name': 'Age'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSuccessfully filled missing Age values with the median value of 28.0.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7N1103703624199\\AppData\\Local\\Temp\\ipykernel_18752\\3985530214.py:144: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column_name].fillna(median, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe missing values in the \"Age\" column of the \"train\" DataFrame have been successfully filled with the median value, which is 28.0. If you need further assistance or analysis, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fill_missing_age_with_median` with `{'df_name': 'train', 'column_name': 'Age'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSuccessfully filled missing Age values with the median value of 28.0.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fill_missing_age_with_median` with `{'df_name': 'test', 'column_name': 'Age'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSuccessfully filled missing Age values with the median value of 27.0.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7N1103703624199\\AppData\\Local\\Temp\\ipykernel_18752\\3985530214.py:144: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column_name].fillna(median, inplace=True)\n",
      "C:\\Users\\7N1103703624199\\AppData\\Local\\Temp\\ipykernel_18752\\3985530214.py:144: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column_name].fillna(median, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe missing values in the \"Age\" column have been successfully filled with the median values for both DataFrames:\n",
      "\n",
      "- In the \"train\" DataFrame, the median value used was 28.0.\n",
      "- In the \"test\" DataFrame, the median value used was 27.0.\n",
      "\n",
      "If you need further assistance or analysis, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def initialize_bedrock_client(\n",
    "    aws_access_key_id, aws_secret_access_key, aws_session_token\n",
    "):\n",
    "    return boto3.client(\n",
    "        \"bedrock-runtime\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        aws_session_token=aws_session_token,\n",
    "        region_name=REGION_NAME,\n",
    "        # config=custom_config,\n",
    "    )\n",
    " \n",
    "REGION_NAME = \"us-east-1\"\n",
    "MODEL_ID = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    " \n",
    "# Setting AWS key\n",
    "# AWS_ACCESS_KEY_ID = \"\"\n",
    "# AWS_SECRET_ACCESS_KEY = \"\"\n",
    "# AWS_SESSION_TOKEN = \"\"\n",
    " \n",
    "# custom_config = Config(\n",
    "#     read_timeout=400,\n",
    "#     connect_timeout=400,\n",
    "#     retries={\"max_attempts\": 3},\n",
    "# )\n",
    "bedrock_runtime = initialize_bedrock_client(\n",
    "        aws_access_key_id, aws_secret_access_key, aws_session_token\n",
    "    )\n",
    "llm = BedrockChat(model_id=MODEL_ID, client=bedrock_runtime)\n",
    " \n",
    "system_template = \"\"\"You are a female who is specialized in financial analysis and credit analysis for auto loans. Your task is to analyze financial data and provide insights.\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template_company_fin = \"\"\"Analyze the following data {company_profile}.\"\"\"\n",
    " \n",
    "human_message_prompt_company_fin = HumanMessagePromptTemplate.from_template(\n",
    "        human_template_company_fin\n",
    "    )\n",
    "chat_prompt_comp_info = ChatPromptTemplate.from_messages(\n",
    "        [system_message_prompt, human_message_prompt_company_fin]\n",
    "    )\n",
    "messages_comp_info = chat_prompt_comp_info.format_prompt(\n",
    "        company_profile=\"The company is a leading auto loan provider with a diverse portfolio of customers. The company has been in operation for over 10 years and has a strong market presence. The company offers competitive interest rates and flexible repayment options to its customers. The company has a robust risk management framework in place to mitigate potential losses.\"\n",
    "    ).to_messages()\n",
    " \n",
    "response = llm.invoke(\n",
    "        messages_comp_info, temperature=0.0, max_tokens=4096, top_p=0.9999\n",
    "    )\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2381890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
